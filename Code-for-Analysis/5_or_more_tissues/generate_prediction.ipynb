{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb27d3-8f43-414d-9435-a4842d6eaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.deprecation import deprecated\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "from decimal import Decimal\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd69f2-c98f-4583-8cb0-a0c58a5b0b34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of regions in allen ontology: 1839\n",
      "Amygdala --> amygdala ;  number of regions in allen: 135\n",
      "Anterior_cingulate_cortex_BA24 --> cingulate gyrus, frontal part ;  number of regions in allen: 7\n",
      "Caudate_basal_ganglia --> caudate nucleus ;  number of regions in allen: 10\n",
      "Cerebellum --> cerebellum ;  number of regions in allen: 95\n",
      "Cortex --> frontal lobe ;  number of regions in allen: 87\n",
      "Hippocampus --> hippocampal formation ;  number of regions in allen: 30\n",
      "Hypothalamus --> hypothalamus ;  number of regions in allen: 176\n",
      "Nucleus_accumbens_basal_ganglia --> nucleus accumbens ;  number of regions in allen: 3\n",
      "Putamen_basal_ganglia --> putamen ;  number of regions in allen: 3\n",
      "Substantia_nigra --> substantia nigra ;  number of regions in allen: 7\n",
      "\n",
      "\n",
      "Amygdala  # regions expired: 6\n",
      "Anterior_cingulate_cortex_BA24  # regions expired: 2\n",
      "Caudate_basal_ganglia  # regions expired: 3\n",
      "Cerebellum  # regions expired: 9\n",
      "Cortex  # regions expired: 14\n",
      "Hippocampus  # regions expired: 6\n",
      "Hypothalamus  # regions expired: 3\n",
      "Nucleus_accumbens_basal_ganglia  # regions expired: 1\n",
      "Putamen_basal_ganglia  # regions expired: 1\n",
      "Substantia_nigra  # regions expired: 2\n",
      "Total number of intersected region between allen and gtex: 103\n",
      "Total number of used allen region for generating regions for gtex: 47\n",
      "Total number of unseen allen regions when generating regions for gtex: 56\n",
      "\n",
      "\n",
      "level 1: 103\n",
      "[4012, 4013, 4014, 4023, 4024, 4030, 4031, 4039, 4045, 4048, 4051, 4060, 4074, 4079, 4087, 4088, 4098, 4099, 4106, 4107, 4113, 4114, 4120, 4121, 4135, 4136, 4142, 4143, 4149, 4150, 4151, 4158, 4160, 4166, 4178, 4186, 4187, 4193, 4194, 4200, 4201, 4214, 4223, 4224, 4230, 4244, 4245, 4251, 4254, 4255, 4256, 4257, 4258, 4270, 4273, 4280, 4281, 4282, 4288, 4291, 4296, 4322, 4329, 4342, 4351, 4360, 4367, 4379, 4395, 4400, 4409, 4417, 4432, 4437, 4440, 4506, 4507, 4518, 4542, 4679, 4720, 4722, 4723, 4725, 4738, 4739, 4740, 4741, 4782, 9054, 9067, 9074, 9075, 9161, 9492, 9520, 9543, 9561, 9598, 9614, 9677, 9698, 13005]\n",
      "level 2: 79\n",
      "[4097, 4105, 4112, 4119, 4134, 4141, 4148, 4157, 4165, 4177, 4185, 12891, 12892, 12893, 12894, 12895, 4192, 12896, 12898, 12899, 12900, 12901, 4199, 12910, 4213, 12920, 12921, 12922, 12924, 12925, 4222, 12927, 12929, 4229, 12935, 12937, 12938, 12939, 12940, 12946, 4243, 4269, 4272, 4287, 4290, 13004, 4321, 4328, 4341, 4350, 4359, 4366, 4378, 9519, 9542, 9560, 9053, 9066, 9073, 9597, 9613, 4505, 4517, 4011, 9133, 4022, 4029, 4541, 4038, 9160, 4044, 9676, 4047, 4050, 4059, 9697, 4072, 4078, 4086]\n",
      "level 3: 45\n",
      "[4096, 12931, 4228, 4104, 12936, 4111, 4242, 4118, 4504, 4249, 4132, 4133, 4391, 9512, 4393, 9002, 4010, 4140, 4780, 4268, 9132, 9135, 4009, 4147, 4275, 4277, 4278, 4021, 4665, 4156, 4028, 4540, 4035, 4293, 4184, 4191, 4198, 4327, 4071, 9072, 9587, 4212, 4085, 12923, 4221]\n",
      "level 4: 23\n",
      "[12930, 4103, 4132, 4006, 4007, 4392, 4008, 9001, 4009, 9131, 4391, 9002, 9512, 4393, 4275, 4276, 4277, 4540, 4180, 4696, 4084, 4219, 4220]\n",
      "level 5: 13\n",
      "[4833, 4005, 4006, 4391, 4008, 4007, 9001, 4392, 4275, 4084, 4276, 4697, 4219]\n",
      "level 6: 8\n",
      "[4005, 4006, 4007, 4391, 4008, 4275, 4696, -1]\n",
      "level 7: 5\n",
      "[4833, 4005, 4006, 4007, -1]\n",
      "level 8: 3\n",
      "[4005, 4006, -1]\n",
      "level 9: 2\n",
      "[4005, -1]\n",
      "level 10: 1\n",
      "[-1]\n",
      "There are 245 nodes in total\n"
     ]
    }
   ],
   "source": [
    "# initial settings\n",
    "# train the model on GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "region_pick = ['Amygdala', 'Anterior_cingulate_cortex_BA24', 'Caudate_basal_ganglia', \n",
    "               'Cerebellar_Hemisphere', 'Frontal_Cortex_BA9', 'Hippocampus', 'Hypothalamus', \n",
    "               'Nucleus_accumbens_basal_ganglia', 'Putamen_basal_ganglia', 'Substantia_nigra']\n",
    "\n",
    "# name difference\n",
    "def find_allen_name(gtex_region):\n",
    "    if gtex_region=='Cerebellar_Hemisphere':\n",
    "        allen_name = 'Cerebellum'\n",
    "    elif gtex_region=='Frontal_Cortex_BA9':\n",
    "        allen_name = 'Cortex'\n",
    "    else:\n",
    "        allen_name = gtex_region\n",
    "        \n",
    "    return allen_name\n",
    "\n",
    "# settings\n",
    "all_ids = ['10021', '12876', '14380', '15496', '15697', '9861']\n",
    "\n",
    "# path\n",
    "allen_data_path = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/data/allen_data/allen/'\n",
    "save_path = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/data/allen_data/quantile_normalized_allen/'\n",
    "\n",
    "GeneExpression_allen_dict = {}\n",
    "# iterate over all 6 subjects\n",
    "for i in range(len(all_ids)):\n",
    "    donor = all_ids[i]\n",
    "    file_name = save_path + \"normalized_expr_\" + donor + \".csv\"\n",
    "    normalized_mat = pd.read_csv(file_name, header = 0)\n",
    "    normalized_mat = normalized_mat.set_index('gene_symbol')\n",
    "    GeneExpression_allen_dict[donor] = normalized_mat\n",
    "    \n",
    "    \n",
    "ontology_path = allen_data_path + 'normalized_microarray_donor' + '9861' + '/Ontology.csv'\n",
    "ontology = pd.read_csv(ontology_path, header = 0)\n",
    "# From the ontology file, find the sub-regions in allen under gtex region\n",
    "gtex_map_path = allen_data_path + \"map_gtex_structure.txt\"\n",
    "gTex_map_dict = {}\n",
    "print(\"Total number of regions in allen ontology:\", ontology.shape[0])\n",
    "for i in open(gtex_map_path):\n",
    "    i = i.strip().split(\"\\t\")\n",
    "    gtex_region = i[0].strip()\n",
    "    allen_region = i[1].strip()\n",
    "    if((allen_region == \"none?\") | (allen_region == 'pituitary body')):\n",
    "        continue\n",
    "    covered_allen_region = ontology.loc[(ontology['name']==allen_region) | ontology['structure_id_path'].str.startswith(ontology.loc[ontology['name']==allen_region, 'structure_id_path'].values[0]), 'id']\n",
    "    gTex_map_dict[gtex_region] = covered_allen_region.tolist()\n",
    "    print(gtex_region, \"-->\", allen_region, \";  number of regions in allen:\", len(covered_allen_region))\n",
    "print(\"\\n\")\n",
    "    \n",
    "    \n",
    "intersected_region = GeneExpression_allen_dict['9861'].columns.tolist()\n",
    "used_intersected_region_dict = {}\n",
    "# unseen_intersected_region_dict = {}\n",
    "for gtex_region, covered_allen_region in gTex_map_dict.items():\n",
    "    used_region_list = [x for x in intersected_region if int(x) in covered_allen_region]\n",
    "    used_intersected_region_dict[gtex_region] = used_region_list\n",
    "    print(gtex_region, \" # regions expired:\", len(used_region_list))\n",
    "num_used_region = sum(len(value) for value in used_intersected_region_dict.values())\n",
    "print(\"Total number of intersected region between allen and gtex:\", len(intersected_region))\n",
    "print(\"Total number of used allen region for generating regions for gtex:\", num_used_region)\n",
    "print(\"Total number of unseen allen regions when generating regions for gtex:\", len(intersected_region)-num_used_region)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# read the summarized allen data (in gtex format) into a dictionary\n",
    "save_path = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/data/allen_data/quantile_normalized_allen/'\n",
    "# find the file and read it into a dictionary\n",
    "summarized_gtex_dict = {}\n",
    "for file_name in os.listdir(save_path):\n",
    "    if file_name.endswith('-gtex.txt'):\n",
    "        key = file_name.split('-gtex.txt')[0]\n",
    "        file_path = os.path.join(save_path, file_name)\n",
    "        mat = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "        #mat = mat.iloc[:-1]\n",
    "        # Store the dataframe in the dictionary with the key\n",
    "        summarized_gtex_dict[key] = mat\n",
    "        \n",
    "\n",
    "# Load gtex data\n",
    "data_dir = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/12052023/'\n",
    "gt = pd.read_csv(data_dir+\"new_normed_gtex_gtex_allen_gene.txt\", low_memory=False, index_col=0, sep=\"\\t\")\n",
    "\n",
    "# build a dictionary to count the freq of each subject \n",
    "sample_subject_list = gt.loc['subject'].tolist()\n",
    "subject_count_dict = {}\n",
    "for s in sample_subject_list:\n",
    "    if s in subject_count_dict:\n",
    "        subject_count_dict[s] = subject_count_dict[s] + 1\n",
    "    else:\n",
    "        subject_count_dict[s] = 1\n",
    "# build a dictionary to count the freq of each region\n",
    "sample_region_list = gt.loc['region'].tolist()\n",
    "region_count_dict = {}\n",
    "for s in sample_region_list:\n",
    "    if s in region_count_dict:\n",
    "        region_count_dict[s] = region_count_dict[s] + 1\n",
    "    else:\n",
    "        region_count_dict[s] = 1  \n",
    "\n",
    "# find the subjects that have all 10 regions\n",
    "pick_subject = [s for s, c in subject_count_dict.items() if c==10]\n",
    "# build a dictionary for exp data for each subject in gtex who has all 10 brain regions\n",
    "exp_gtex_dict = {}\n",
    "for subject in pick_subject:\n",
    "    submat = gt[gt.columns[gt.iloc[1]==subject]]\n",
    "    submat.columns = submat.loc['region',:]\n",
    "    submat = submat.iloc[2:,]\n",
    "    submat.index.names = ['gene_id']\n",
    "    submat = submat.sort_values(by=['gene_id'])\n",
    "    submat = submat[region_pick]\n",
    "    # And also, transform the dataframe in gtex from strings to numbers\n",
    "    submat = submat.apply(pd.to_numeric, errors='ignore')\n",
    "    # Take the average if more than 1 sample have the same gene names\n",
    "    submat = submat.groupby(submat.index).mean()\n",
    "    exp_gtex_dict[subject] = submat\n",
    "# find 30 gtex subjects\n",
    "sub_all_ids = list(exp_gtex_dict.keys())\n",
    "    \n",
    "    \n",
    "# gene_module = pd.read_csv(allen_data_path+'41593_2015_BFnn4171_MOESM97_ESM.csv')\n",
    "allen_gene_list = GeneExpression_allen_dict['9861'].index\n",
    "gtex_gene_list = exp_gtex_dict['GTEX-N7MT'].index\n",
    "overlapped_gene_list = [x for x in gtex_gene_list if x in allen_gene_list]  # 15044 genes here\n",
    "# allen subject gene expression profile on the overlapped genes\n",
    "exp_allen_dict = {}\n",
    "for key, mat in GeneExpression_allen_dict.items():\n",
    "    exp_allen_dict[key] = mat.loc[overlapped_gene_list]\n",
    "# summarized gtex info for allen subjects on the overlapped genes\n",
    "summ_gtex_info = {}\n",
    "for key, mat in summarized_gtex_dict.items():\n",
    "    summ_gtex_info[key] = mat.loc[overlapped_gene_list]\n",
    "# rename the Cerebellum to Cerebellar_Hemisphere and Cortex to Frontal_Cortex_BA for allen people\n",
    "for subject, mat in summ_gtex_info.items():\n",
    "    mat.columns = exp_gtex_dict['GTEX-N7MT'].columns\n",
    "\n",
    "\n",
    "# gene embeddings\n",
    "g_emb_error = 0.035\n",
    "g_emb_size = 2 ** 4\n",
    "g_emb_path = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/02162024/ATG_91_103/'\n",
    "g_emb_name = f'allen_gtex_gene_emb_all6subjects_size_{g_emb_size}_pearson_err_{g_emb_error}_intersected103.csv'\n",
    "# np.savetxt(g_emb_path+g_emb_name, pretrain_g_emb, delimiter=',')\n",
    "# read the pretrained gene embedding\n",
    "pretrain_g_emb = np.genfromtxt(g_emb_path+g_emb_name, delimiter=',', dtype=np.float32)\n",
    "import pickle\n",
    "# Load the gene names from the file\n",
    "with open(g_emb_path+g_emb_name+'_genenames.pkl', 'rb') as file:\n",
    "    gene_emb_names_list = pickle.load(file)\n",
    "    \n",
    "\n",
    "# Build the edge list\n",
    "# From the Ontology find the node relationship list\n",
    "onto_file_path = 'normalized_microarray_donor10021/Ontology.csv'\n",
    "onto_file_path = os.path.join(allen_data_path, onto_file_path)\n",
    "ontology = pd.read_csv(onto_file_path)\n",
    "ontology_id = ontology.loc[:, ['id', 'parent_structure_id']]\n",
    "# set the parent node of 4005 to -1\n",
    "ontology_id.iloc[0,1] = -1\n",
    "ontology_id['parent_structure_id'] = ontology_id['parent_structure_id'].astype(int)\n",
    "# View the nodes in a hierarchical way\n",
    "node_child = [int(x) for x in intersected_region]\n",
    "all_node = []\n",
    "for i in range(1,20):\n",
    "    if i==1:\n",
    "        print(f\"level {i}: {len(node_child)}\")\n",
    "        print(node_child)\n",
    "        all_node.append(node_child)\n",
    "    if len(node_child)==1:\n",
    "        break\n",
    "    if i!=1:\n",
    "        node_parent = []\n",
    "        for node in node_child:\n",
    "            pos = ontology_id['id'].index[ontology_id['id']==node]\n",
    "            # skip if it's already the ancestor\n",
    "            if len(pos)==0: continue\n",
    "            parent = ontology_id['parent_structure_id'][pos].values[0]\n",
    "            node_parent.append(parent)\n",
    "        node_parent = set(node_parent)\n",
    "        node_child = [x for x in node_parent]\n",
    "        print(f\"level {i}: {len(node_child)}\")\n",
    "        print(node_child)\n",
    "        all_node.append(node_child)\n",
    "repeated_nodes = [x for y in all_node for x in y]\n",
    "pick_nodes = set(repeated_nodes)\n",
    "print(f\"There are {len(pick_nodes)} nodes in total\")\n",
    "\n",
    "pick_nodes = [x for x in pick_nodes]\n",
    "pick_nodes.sort()\n",
    "# exclude the ancestor node (4005) and the '-1' node\n",
    "intersected_nodes_child = pick_nodes[2:]\n",
    "child_nodes_chr = list(exp_allen_dict['9861'].columns)\n",
    "child_nodes = [int(x) for x in child_nodes_chr]\n",
    "# append other hyper-level nodes to the pick_nodes\n",
    "for x in intersected_nodes_child:\n",
    "    if x not in child_nodes:\n",
    "        child_nodes.append(x)\n",
    "# find the parent nodes for the pick_nodes\n",
    "parent_nodes = []\n",
    "for x in child_nodes:\n",
    "    pos = ontology_id['id'].index[ontology_id['id']==x][0]\n",
    "    parent = ontology_id['parent_structure_id'][pos]\n",
    "    parent_nodes.append(parent)\n",
    "    \n",
    "for _ in range(len(parent_nodes)):\n",
    "    length = len(parent_nodes)\n",
    "    for i in range(length):\n",
    "        cid = child_nodes[i]\n",
    "        pid = parent_nodes[i]\n",
    "        if pid!=4005:\n",
    "            # find how many children this parent node has\n",
    "            count1 = parent_nodes.count(pid)\n",
    "            # if this count is more than one, we don't remove this node\n",
    "            if count1 > 1:\n",
    "                continue\n",
    "            # if this parent node only has one child, we remove it\n",
    "            else:\n",
    "                # find the position of this parent node in the children node list\n",
    "                pidx = child_nodes.index(pid)\n",
    "                # find the grandparent\n",
    "                ppid = parent_nodes[pidx]\n",
    "                # remove this parent and directly connect the child to its grandparent\n",
    "                child_nodes[pidx] = cid\n",
    "                child_nodes.pop(i)\n",
    "                parent_nodes.pop(i)\n",
    "                break\n",
    "    if len(parent_nodes)==length:\n",
    "        break\n",
    "        \n",
    "# put the leaves at the beginning\n",
    "initial_nodes_chr = list(exp_allen_dict['9861'].columns)\n",
    "new_child_nodes = [int(x) for x in initial_nodes_chr]\n",
    "new_parent_nodes = []\n",
    "for x in child_nodes:\n",
    "    if x not in new_child_nodes:\n",
    "        new_child_nodes.append(x)\n",
    "for x in new_child_nodes:\n",
    "    new_parent_nodes.append(parent_nodes[child_nodes.index(x)])\n",
    "\n",
    "# put all nodes together in order so we can re-assign node id\n",
    "all_nodes = new_child_nodes.copy()\n",
    "for x in new_parent_nodes:\n",
    "    if x not in all_nodes:\n",
    "        all_nodes.append(x)\n",
    "\n",
    "# re-index all the nodes and all the dataframe\n",
    "child_nodes_idx = []\n",
    "parent_nodes_idx = []\n",
    "for node in new_child_nodes:\n",
    "    child_nodes_idx.append(all_nodes.index(node))\n",
    "for node in new_parent_nodes:\n",
    "    parent_nodes_idx.append(all_nodes.index(node))\n",
    "\n",
    "\n",
    "# Model pre-setting\n",
    "# train the model on GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# other settings\n",
    "N_gene = len(exp_allen_dict['9861'])\n",
    "N_node = len(child_nodes_idx)+1\n",
    "n_node = len(intersected_region)\n",
    "# define the edge list\n",
    "# add edges between region nodes\n",
    "edge_index_1 = [[child_nodes_idx[i], parent_nodes_idx[i]] for i in range(len(child_nodes_idx))]\n",
    "edge_index_2 = [[parent_nodes_idx[i], child_nodes_idx[i]] for i in range(len(child_nodes_idx))]\n",
    "edge_index = edge_index_1 + edge_index_2\n",
    "for i in range(N_node):\n",
    "    edge_index.append([i, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1dd62-2ba2-4bc8-ba8e-6557222b196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gtex data\n",
    "data_dir = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/12052023/'\n",
    "gt = pd.read_csv(data_dir+\"new_normed_gtex_gtex_allen_gene.txt\", low_memory=False, index_col=0, sep=\"\\t\")\n",
    "region_pick = ['Amygdala', 'Anterior_cingulate_cortex_BA24', 'Caudate_basal_ganglia', \n",
    "               'Cerebellar_Hemisphere', 'Frontal_Cortex_BA9', 'Hippocampus', 'Hypothalamus', \n",
    "               'Nucleus_accumbens_basal_ganglia', 'Putamen_basal_ganglia', 'Substantia_nigra']\n",
    "\n",
    "# build a dictionary to count the freq of each subject \n",
    "sample_subject_list = gt.loc['subject'].tolist()\n",
    "subject_region_mat = pd.DataFrame(np.zeros((len(set(sample_subject_list)), len(region_pick)), dtype=int))\n",
    "subject_region_mat.index = sorted(set(sample_subject_list))\n",
    "subject_region_mat.columns = region_pick\n",
    "for i in range(gt.shape[1]):\n",
    "    region = gt.loc['region'][i]\n",
    "    subject = gt.loc['subject'][i]\n",
    "    region_idx = region_pick.index(region)\n",
    "    subject_idx = subject_region_mat.index.tolist().index(subject)\n",
    "    subject_region_mat.iloc[subject_idx, region_idx] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae5b2c-d3a0-4a4d-9f9c-142cb91fca8d",
   "metadata": {},
   "source": [
    "### Generate prediction for each tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd460f35-0a3c-40b5-9ae7-7d9d685b4928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_GO_generator_by_region(t_epoch, f_epoch, missing_N, pred_region):\n",
    "    data_dir = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/02162024/ATG_91_103/Result/'\n",
    "    if f_epoch==0:\n",
    "        model_name = f'ATG_91_103_{pred_region}_epoch_{t_epoch}_bf_architecture.pth'\n",
    "        weights_name = f'ATG_91_103_{pred_region}_epoch_{t_epoch}_bf_weights.pth'\n",
    "    else:\n",
    "        model_name = f'ATG_91_103_{pred_region}_trainable_GNN_af_epoch_{t_epoch}_finetuning_epoch_{f_epoch}_architecture.pth'\n",
    "        weights_name = f'ATG_91_103_{pred_region}_trainable_GNN_af_epoch_{t_epoch}_finetuning_epoch_{f_epoch}_weights.pth'\n",
    "    model = torch.load(data_dir+model_name)\n",
    "    model.load_state_dict(torch.load(data_dir+weights_name))\n",
    "    # find the predicted region and indices\n",
    "    nodes_for_pred_gtex_region = used_intersected_region_dict[find_allen_name(pred_region)]\n",
    "    nodes_for_pred_gtex_region_idx = [new_child_nodes.index(int(x)) for x in nodes_for_pred_gtex_region]\n",
    "    # use lm model to fill other missing regions\n",
    "    subject_w_10_r = [s for s in subject_region_mat.index if subject_region_mat.loc[s].sum()==10]\n",
    "    go_pred_dict = {}\n",
    "    for subject in subject_region_mat.index:\n",
    "        if subject_region_mat.loc[subject, pred_region]==1:\n",
    "            for i in range(gt.shape[1]):\n",
    "                if ((gt.loc['region'][i]==pred_region) & (gt.loc['subject'][i]==subject)):\n",
    "                    go_pred_dict[subject] = pd.to_numeric(gt.iloc[2:,i])\n",
    "        else:\n",
    "            # predict the missing region using LM from GTEx + GO:\n",
    "            if subject_region_mat.loc[subject].sum()>=(10-missing_N):\n",
    "                other_9_region_dict = {}\n",
    "                # these are the existing regions besides the predicted region\n",
    "                x_region = [r for r in region_pick if subject_region_mat.loc[subject, r]==1 if r!=pred_region]\n",
    "                for region in x_region:\n",
    "                    for i in range(gt.shape[1]):\n",
    "                        if ((gt.loc['region'][i]==region) & (gt.loc['subject'][i]==subject)):\n",
    "                            other_9_region_dict[region] = pd.to_numeric(gt.iloc[2:,i])\n",
    "                # these are the regions to fill with lm model\n",
    "                fill_region = [r for r in region_pick if r not in x_region if r!=pred_region]\n",
    "                # build the inputs for GO model\n",
    "                if len(fill_region)!=0:\n",
    "                    # build the x regions matrix\n",
    "                    train_dfs = [exp_gtex_dict[key].loc[:,x_region] for key in subject_w_10_r]\n",
    "                    Xtrain = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "                    Xtrain = sm.add_constant(Xtrain)\n",
    "                    pick_col = [i for i in range(gt.shape[1]) if gt.loc['subject'][i]==subject]\n",
    "                    Xtest = gt.iloc[:,pick_col]\n",
    "                    Xtest.columns = Xtest.loc['region']\n",
    "                    Xtest = Xtest.drop(['region', 'subject'])\n",
    "                    Xtest = Xtest.loc[:,x_region]\n",
    "                    Xtest = Xtest.apply(pd.to_numeric)\n",
    "                    Xtest = sm.add_constant(Xtest)\n",
    "                    for lm_region in fill_region:\n",
    "                        y_region = lm_region\n",
    "                        # build the y region\n",
    "                        train_preds = [exp_gtex_dict[key].loc[:,y_region] for key in subject_w_10_r]\n",
    "                        ytrain = pd.concat(train_preds, axis=0, ignore_index=True)\n",
    "                        # build the lm model\n",
    "                        fmod = sm.OLS(ytrain, Xtrain).fit()\n",
    "                        # prediction\n",
    "                        pred = fmod.predict(Xtest)\n",
    "                        other_9_region_dict[lm_region] = pred\n",
    "                # build the inputs for GO model\n",
    "                sorted_region = [r for r in region_pick if r!=pred_region]\n",
    "                input_mat = pd.DataFrame.from_dict(other_9_region_dict)\n",
    "                input_mat.index = gt.index[2:]\n",
    "                input_mat = input_mat.loc[:,sorted_region]\n",
    "                # run GO model\n",
    "                gen_tuple = torch.tensor(np.arange(N_gene), dtype=torch.long)\n",
    "                x_reg_exp = torch.tensor(input_mat.values).float()           \n",
    "                with torch.no_grad():\n",
    "                    concat_pred = model(nodes_for_pred_gtex_region_idx, gen_tuple, x_reg_exp, edge_index, N_gene).reshape(-1)\n",
    "                go_pred_dict[subject] = concat_pred.detach().cpu()\n",
    "    # generate the final output\n",
    "    pred_mat = pd.DataFrame.from_dict(go_pred_dict)\n",
    "    pred_mat.index = gt.index[2:]\n",
    "    \n",
    "    return pred_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77212b-0673-4286-9642-794ef0ce5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_pick = ['Amygdala', 'Anterior_cingulate_cortex_BA24', 'Caudate_basal_ganglia', \n",
    "#                'Cerebellar_Hemisphere', 'Frontal_Cortex_BA9', 'Hippocampus', 'Hypothalamus', \n",
    "#                'Nucleus_accumbens_basal_ganglia', 'Putamen_basal_ganglia', 'Substantia_nigra']\n",
    "\n",
    "# # build a dictionary to count the freq of each subject \n",
    "# sample_subject_list = gt.loc['subject'].tolist()\n",
    "# subject_region_mat = pd.DataFrame(np.zeros((len(set(sample_subject_list)), len(region_pick)), dtype=int))\n",
    "# subject_region_mat.index = sorted(set(sample_subject_list))\n",
    "# subject_region_mat.columns = region_pick\n",
    "# for i in range(gt.shape[1]):\n",
    "#     region = gt.loc['region'][i]\n",
    "#     subject = gt.loc['subject'][i]\n",
    "#     region_idx = region_pick.index(region)\n",
    "#     subject_idx = subject_region_mat.index.tolist().index(subject)\n",
    "#     subject_region_mat.iloc[subject_idx, region_idx] = 1\n",
    "\n",
    "# # generate prediction for every tissue\n",
    "# t_epoch = 300\n",
    "# f_epoch = 500\n",
    "# missing_N = 5\n",
    "# # generate prediction\n",
    "# for pred_region in region_pick:\n",
    "#     go_mat = gen_GO_generator_by_region(t_epoch, f_epoch, missing_N, pred_region)\n",
    "#     save_dir = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/02162024/ATG_8_or_less/Prediction/'\n",
    "#     csv_file = f'{pred_region}_{t_epoch}_{f_epoch}_{missing_N}_LMfromGTEx.csv'\n",
    "#     go_mat.to_csv(save_dir+csv_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb9086-63a3-48d5-b9fd-ce5a28458e22",
   "metadata": {},
   "source": [
    "### Generate prediction for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c792042b-6227-40e0-b64b-04d20b8e08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gtex_regions_LM_fromGTEx(subject):\n",
    "    # use lm model to fill other missing regions\n",
    "    subject_w_10_r = [s for s in subject_region_mat.index if subject_region_mat.loc[s].sum()==10]\n",
    "    gtex_region_to_predict_dict = {}\n",
    "    # find existing regions\n",
    "    x_region = [r for r in region_pick if subject_region_mat.loc[subject, r]==1]\n",
    "    for region in x_region:\n",
    "        for i in range(gt.shape[1]):\n",
    "            if ((gt.loc['region'][i]==region) & (gt.loc['subject'][i]==subject)):\n",
    "                gtex_region_to_predict_dict[region] = pd.to_numeric(gt.iloc[2:,i])\n",
    "    # these are the regions to be filled with lm model\n",
    "    fill_region = [r for r in region_pick if r not in x_region]\n",
    "    if len(fill_region)!=0:\n",
    "        # build the x regions matrix\n",
    "        train_dfs = [exp_gtex_dict[key].loc[:,x_region] for key in subject_w_10_r]\n",
    "        Xtrain = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "        Xtrain = sm.add_constant(Xtrain)\n",
    "        pick_col = [i for i in range(gt.shape[1]) if gt.loc['subject'][i]==subject]\n",
    "        Xtest = gt.iloc[:,pick_col]\n",
    "        Xtest.columns = Xtest.loc['region']\n",
    "        Xtest = Xtest.drop(['region', 'subject'])\n",
    "        Xtest = Xtest.loc[:,x_region]\n",
    "        Xtest = Xtest.apply(pd.to_numeric)\n",
    "        Xtest = sm.add_constant(Xtest)\n",
    "        for lm_region in fill_region:\n",
    "            y_region = lm_region\n",
    "            # build the y region\n",
    "            train_preds = [exp_gtex_dict[key].loc[:,y_region] for key in subject_w_10_r]\n",
    "            ytrain = pd.concat(train_preds, axis=0, ignore_index=True)\n",
    "            # build the lm model\n",
    "            fmod = sm.OLS(ytrain, Xtrain).fit()\n",
    "            # prediction\n",
    "            pred = fmod.predict(Xtest)\n",
    "            gtex_region_to_predict_dict[lm_region] = pred\n",
    "    # build the inputs for GO model\n",
    "    input_mat = pd.DataFrame.from_dict(gtex_region_to_predict_dict)\n",
    "    input_mat.index = gt.index[2:]\n",
    "    input_mat = input_mat.loc[:,region_pick]\n",
    "        \n",
    "    return input_mat\n",
    "\n",
    "# generate go model input using linear regression model\n",
    "def gen_allen_regions_LM_fromGTEx(t_epoch, f_epoch, status, subject):\n",
    "    # generate the input 10 gtex regions\n",
    "    input_mat = gen_gtex_regions_LM_fromGTEx(subject)\n",
    "    # model directory and load the model\n",
    "    data_dir = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/02162024/ATG_10_103/Result/'\n",
    "    if f_epoch==0:\n",
    "        model_name = f'ATG_10_103_epoch_{t_epoch}_bf_architecture.pth'\n",
    "        weights_name = f'ATG_10_103_epoch_{t_epoch}_bf_weights.pth'\n",
    "    else:\n",
    "        if status==\"freeze\":\n",
    "            model_name = f'ATG_10_103_freeze_GNN_af_epoch_{t_epoch}_finetuning_epoch_{f_epoch}_architecture.pth'\n",
    "            weights_name = f'ATG_10_103_freeze_GNN_af_epoch_{t_epoch}_finetuning_epoch_{f_epoch}_weights.pth'\n",
    "        else:\n",
    "            model_name = f'ATG_10_103_af_epoch_{t_epoch}_finetuning_epoch_{f_epoch}_architecture.pth'\n",
    "            weights_name = f'ATG_10_103_af_epoch_{t_epoch}_finetuning_epoch_{f_epoch}_weights.pth'            \n",
    "    model = torch.load(data_dir+model_name).to(device)\n",
    "    model.load_state_dict(torch.load(data_dir+weights_name))\n",
    "    # run GO model and get the prediction\n",
    "    model.eval()\n",
    "    exp_dict = {}\n",
    "    gtex_exp_10 = torch.tensor(input_mat.values).float().to(device)\n",
    "    gen_tuple = torch.tensor(np.arange(N_gene), dtype=torch.long).to(device)\n",
    "    keys = list(exp_allen_dict[all_ids[0]].columns)\n",
    "    for region in keys:\n",
    "        reg_id = keys.index(region)\n",
    "        pred = model([reg_id], gen_tuple, gtex_exp_10, edge_index, N_gene).reshape(-1)\n",
    "        exp_dict[region] = pred.cpu().detach().numpy()\n",
    "    exp_mat = pd.DataFrame(exp_dict)\n",
    "    exp_mat.index = gt.index[2:]\n",
    "    \n",
    "    return exp_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f51c9f40-3148-4755-8eff-4d0059f9f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prediction for every tissue\n",
    "t_epoch = 300\n",
    "f_epoch = 0\n",
    "status = 'trainable'\n",
    "missing_N = 5\n",
    "# generate prediction\n",
    "go_prediction_dict = {}\n",
    "include_subject = [s for s in subject_region_mat.index if subject_region_mat.loc[s].sum()>=(10-missing_N)]\n",
    "for subject in include_subject:\n",
    "    go_mat = gen_allen_regions_LM_fromGTEx(t_epoch, f_epoch, status, subject)\n",
    "    save_dir = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/02162024/ATG_8_or_less/Prediction/'\n",
    "    folder_name = f'{t_epoch}_{f_epoch}_by_subject/'\n",
    "    csv_file = f'{subject}_{t_epoch}_{f_epoch}_{status}_LMfromGTEx.csv'\n",
    "    # go_mat.to_csv(save_dir+folder_name+csv_file, index=True)\n",
    "    go_prediction_dict[subject] = go_mat\n",
    "    \n",
    "# save the dictionary\n",
    "save_dir = '/project/pi_rachel_melamed_uml_edu/Jianfeng/Allen/src/Pytorch/02162024/ATG_8_or_less/Prediction/'\n",
    "if f_epoch==0:\n",
    "    dict_name = f'gtex_allen_region_epoch_{t_epoch}_missing_N_{missing_N}.pickle'\n",
    "else:\n",
    "    dict_name = f'gtex_allen_region_trainable_GNN_af_epoch_{t_epoch}_fepoch_{f_epoch}_missing_N_{missing_N}.pickle'\n",
    "# Writing the dictionary to a file using pickle\n",
    "with open(save_dir+dict_name, 'wb') as f:\n",
    "    pickle.dump(go_prediction_dict, f)\n",
    "# # Reading the pickled data from file\n",
    "# with open(save_dir+dict_name, 'rb') as f:\n",
    "#     go_prediction_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfd683-3d76-404c-a0b2-45c8bd37340d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Allen_project_cuda",
   "language": "python",
   "name": "allen_project_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
